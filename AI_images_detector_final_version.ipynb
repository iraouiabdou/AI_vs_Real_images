{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#make a hidden directory named .kaggle if it doesn't already exist\n",
        "!mkdir -p ~/.kaggle\n",
        "#copy kaggle.json (I uploaded this API-file previously) into .kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "#change mode to allow only the owner (me) to read and write this file\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "#load the kaggle dataset into my cwd (current working directory) which is /content/\n",
        "!kaggle datasets download -d birdy654/cifake-real-and-ai-generated-synthetic-images\n",
        "#unzip the file quietly (so that it doesn't print 60000 lines)\n",
        "!unzip -qo cifake-real-and-ai-generated-synthetic-images.zip\n",
        "#count the number of files in the train folder\n",
        "!find train -type f | wc -l\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEWzcJrJeQ6X",
        "outputId": "97ec71ed-2909-4563-8c49-59d98f7d676c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images\n",
            "License(s): other\n",
            "Downloading cifake-real-and-ai-generated-synthetic-images.zip to /content\n",
            "  0% 0.00/105M [00:00<?, ?B/s]\n",
            "100% 105M/105M [00:00<00:00, 1.65GB/s]\n",
            "100000\n"
          ]
        }
      ]
    },
    
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "#we implement a pre-processing (transform) pipeline so we adjust the images of the dataset\n",
        "transform = transforms.Compose([\n",
        "    #resize the image to 224*224 pixels which is a standard format of inputs of a ResNet\n",
        "    transforms.Resize((224, 224)),\n",
        "    #transform the image into a tensor that has as dimension [3, 224, 224]\n",
        "    transforms.ToTensor(),\n",
        "    #newpixel = (old - mean)/std, normalize using ImageNet mean/std to match the distribution the model was pre-trained on\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "#store the dataset 'transformed' by our pipeline\n",
        "full_dataset = datasets.ImageFolder('train', transform = transform)\n",
        "\n",
        "#calculate the sizes of the training and testing set\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "\n",
        "#split the data into a training and testing set with an 80/20 split\n",
        "train_data, test_data = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "#set up a dataloader, with shuffle so that the model gets real and fake images randomly\n",
        "#and num_workers set to 2 so that 2 CPU sub-processes work in parallel\n",
        "train_loader = DataLoader(train_data, batch_size = 32, shuffle = True, num_workers = 2)\n",
        "test_loader = DataLoader(test_data, batch_size = 32, shuffle = True, num_workers = 2)"
      ],
      "metadata": {
        "id": "qJ3lMUlHFPPf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#detecting the device we're using\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#storing the ResNet model trained (on IMAGENET1K_V1) that we're going to fine-tune on our specific dataset\n",
        "model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "#replacing the pre-trained ImageNet head (1000 classes) with a binary classifier (Real vs Fake)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "\n",
        "#iterate of the layers of Resnet, if we are NOT in the 3rd, 4th or fully connected layer, freeze the weights to\n",
        "#have less computations and it's faster to train\n",
        "for name, param in model.named_parameters():\n",
        "  if any(x in name for x in {'layer3', 'layer4', 'fc'}):\n",
        "    param.requires_grad = True\n",
        "  else:\n",
        "    param.requires_grad = False\n",
        "\n",
        "#define the optimizer of our neural network, we use filter to remove the frozen weights\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr = 0.01)\n",
        "\n",
        "#move the model to the GPU (or CPU)\n",
        "model = model.to(device)\n",
        "\n",
        "#defining the loss function, we used cross entropy loss since it's a binary classificaiton problem\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#activate training mode\n",
        "model.train()\n",
        "\n",
        "for epoch in range(6):\n",
        "  print(f'Epoch : {epoch + 1}')\n",
        "  for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "    #move the inputs and labels to the GPU (or CPU)\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    #Reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    #forward pass\n",
        "    outputs = model(inputs)\n",
        "    #compute the loss\n",
        "    loss = criterion(outputs, labels)\n",
        "    #backprop\n",
        "    loss.backward()\n",
        "    #update weights\n",
        "    optimizer.step()\n",
        "    if batch_idx % 500 == 0:\n",
        "      print(f'batch : {batch_idx} | loss : {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x-xBmJ7uXbA",
        "outputId": "814a70fc-5953-46d1-aadb-0f8c342b1091",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1\n",
            "batch : 0 | loss : 0.8410\n",
            "batch : 500 | loss : 0.1814\n",
            "batch : 1000 | loss : 0.1923\n",
            "batch : 1500 | loss : 0.2199\n",
            "batch : 2000 | loss : 0.1767\n",
            "Epoch : 2\n",
            "batch : 0 | loss : 0.1312\n",
            "batch : 500 | loss : 0.0403\n",
            "batch : 1000 | loss : 0.2141\n",
            "batch : 1500 | loss : 0.1329\n",
            "batch : 2000 | loss : 0.2021\n",
            "Epoch : 3\n",
            "batch : 0 | loss : 0.0565\n",
            "batch : 500 | loss : 0.1491\n",
            "batch : 1000 | loss : 0.0961\n",
            "batch : 1500 | loss : 0.0343\n",
            "batch : 2000 | loss : 0.0851\n",
            "Epoch : 4\n",
            "batch : 0 | loss : 0.0251\n",
            "batch : 500 | loss : 0.1818\n",
            "batch : 1000 | loss : 0.2372\n",
            "batch : 1500 | loss : 0.0975\n",
            "batch : 2000 | loss : 0.0235\n",
            "Epoch : 5\n",
            "batch : 0 | loss : 0.0206\n",
            "batch : 500 | loss : 0.1868\n",
            "batch : 1000 | loss : 0.1069\n",
            "batch : 1500 | loss : 0.0452\n",
            "batch : 2000 | loss : 0.1091\n",
            "Epoch : 6\n",
            "batch : 0 | loss : 0.1460\n",
            "batch : 500 | loss : 0.1079\n",
            "batch : 1000 | loss : 0.0329\n",
            "batch : 1500 | loss : 0.0387\n",
            "batch : 2000 | loss : 0.0437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#activate evaluation mode\n",
        "model.eval()\n",
        "\n",
        "#count the number of correct predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "#don't compute the gradient since we're in evaluation mode\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    #Get the class index with the highest score for each image in the batch\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    if batch_idx % 100 == 0:\n",
        "      curr_acc = 100 * correct / total\n",
        "      print(f'batch : {batch_idx} | current accuracy : {curr_acc:.2f}%')\n",
        "acc = 100 * correct / total\n",
        "print(f'Accuracy = {acc:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN4fVq48wjRA",
        "outputId": "6e18328b-b19a-4d3e-fd4a-eed1ceaf4c53"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch : 0 | current accuracy : 93.75%\n",
            "batch : 100 | current accuracy : 95.45%\n",
            "batch : 200 | current accuracy : 95.54%\n",
            "batch : 300 | current accuracy : 95.50%\n",
            "batch : 400 | current accuracy : 95.43%\n",
            "batch : 500 | current accuracy : 95.65%\n",
            "batch : 600 | current accuracy : 95.62%\n",
            "Accuracy = 95.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jGCy-KC4EIlC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
